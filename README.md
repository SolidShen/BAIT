# ðŸŽ£ BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target

*ðŸ”¥ðŸ”¥ðŸ”¥ Detecting hidden backdoors in Large Language Models with only black-box access*

**BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target** [[S&P'25](https://arxiv.org/abs/2310.03744)] <br>
[Guangyu Shen*](https://purdue.edu),
[Siyuan Cheng*](https://purdue.edu),
[Zhuo Zhang](https://purdue.edu),
[Guanhong Tao](https://purdue.edu),
[Kaiyuan Zhang](https://purdue.edu),
[Hanxi Guo](https://purdue.edu),
[Lu Yan](https://purdue.edu),
[Xiaolong Jin](https://purdue.edu),
[Shengwei An](https://purdue.edu),
[Shiqing Ma](https://www.umass.edu),
[Xiangyu Zhang](https://purdue.edu) (*Equal Contribution)


## Contents
- [Install](#install)
- [Demo](#Demo)
- [Model Zoo](https://github.com/haotian-liu/LLaVA/blob/main/docs/MODEL_ZOO.md)
- [Dataset](https://github.com/haotian-liu/LLaVA/blob/main/docs/Data.md)
- [Evaluation](#evaluation)

## Install
